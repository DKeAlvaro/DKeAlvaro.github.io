{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "113bdbd0",
   "metadata": {},
   "source": [
    "# Lab instruction: Supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd60184",
   "metadata": {},
   "source": [
    "### First exercise\n",
    "\n",
    "\n",
    "**Objective**  \n",
    "   To implement and perform basic understanfing of KNN, logistic regression and tree-based classifiers.\n",
    "\n",
    "1. **Dataset**\n",
    "   For this lab session we are loading the digits dataset from sklearn. Split the data into test and training data. Make a function that displays the first 25 digits in a grid of 5x5.\n",
    "\n",
    "2. **Learning algorithms**\n",
    "   implement a KNN, a logistic regression and the tree-based classifers.\n",
    "   Train on the traning set and evaluate the classifier on the test. Use the function  ConfusionMatrixDisplay from sklearn.metrics to generate the confusion mettrics on the test set to evaluate the classifiers. Which classifier is best? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da38a422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and splitting the data\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data, labels = load_digits(return_X_y=True)\n",
    "(n_samples, n_features), n_digits = data.shape, np.unique(labels).size\n",
    "X, y = data, labels\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a245ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first 25 digits\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c166b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b5741d",
   "metadata": {},
   "source": [
    "### Second exercise\n",
    "The objective of the second exercise is to compare the generalization of the three compared models. For this we perform the following steps.\n",
    "\n",
    "1. **Generating the data**\n",
    "   Generate  synthetic dataset with the function make_classification within the sklearn.datasets library. The dataset should contain 2 features, 3 classes, 1 cluster per class, 2 informative features, and the class separation is set to 1.0\n",
    "\n",
    "2. **Learning algorithms**\n",
    "   Split the data also in test and training sets. 20% of the points are used for testing. Train a KNN classifier, a logistic regression model and a Tree classifier.\n",
    "\n",
    "3. **Visualize the decision boundaries**\n",
    "   Make a function which shows the decision boundary and displays the training points on it. To do so use the function DecisionBoundaryDisplay from from sklearn.inspection. Display the decision boundary for the three classifiers. How the class separion differs? Compare the decision boundaries between the models.\n",
    "\n",
    "4. **Repeating with a lower margin**\n",
    "   In your data generator set the class separation to 0.45 and run again your training and display functions. How has the decision bundary changed? Which model is more prone to overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba8e3242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6d37cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "def showDecisionBou8undary(X_train, y_train, classif):\n",
    "    # Add you code here\n",
    "    pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4823af99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logR = LogisticRegression()\n",
    "logR.fit(X_train, y_train)\n",
    "showDecisionBou8undary(X_train, y_train, logR)\n",
    "\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=4)\n",
    "neigh.fit(X_train, y_train)\n",
    "showDecisionBou8undary(X_train, y_train, neigh)\n",
    "\n",
    "# Tree-based classifier\n",
    "treeC = tree.DecisionTreeClassifier()\n",
    "treeC.fit(X_train, y_train)\n",
    "showDecisionBou8undary(X_train, y_train, treeC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dbb7f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0807c92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
