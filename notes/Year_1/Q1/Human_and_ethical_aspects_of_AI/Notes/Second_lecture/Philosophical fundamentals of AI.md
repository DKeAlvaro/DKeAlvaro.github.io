# Philosophical fundamentals of AI - Lecture 2

Q: What are the two main parts of the lecture "Philosophical fundamentals of AI"?
A: Part 1 is "Practitioner foundations" and Part 2 is "Philosophical foundations for intelligent machines" (Page 2).

Q: How does the lecture define "AI" (Artificial Intelligence)?
A: (designed) learning + reasoning machines (Page 3).

Q: How does the lecture define "Learning"?
A: Getting better at a task through experience (Page 3).

Q: What two things does "Learning" require?
A: A metric that measures improvement (better/worse) and being relative to a specific task (Page 3).

Q: How does the lecture define "Reasoning"?
A: Logical deduction or probabilistic inference (Page 3).

Q: What is the goal of European AI policy as identified in the "White paper on AI"?
A: Trustworthy AI (Page 7).

Q: The "White paper on AI" identifies trustworthy AI as necessarily connected with what three things?
A: Robustness, legality, and ethical standards (Page 7).

Q: What is the "Plus One" in the "Four Principles Plus One" of ethical standards?
A: Explainability (Page 7).

Q: What is "Robust AI"?
A: The property of an AI model that its sensitivity/specificity will continue to obtain for new data (Page 8).

Q: What is the difference between "weak robustness" and "strong robustness"?
A: Weak robustness applies to new data that is similar, while strong robustness applies to new data that is different (Page 8).

Q: What is an "argument"?
A: A set of propositions containing at least one premise and one conclusion, where premises are intended to support the conclusion (Page 9).

Q: What is "Validity" in a deductive argument?
A: The property that if the premises are true, then the conclusion is guaranteed to be true (Page 10).

Q: What is a "sound" argument?
A: An argument that is valid and has all true premises (Page 11).

Q: What is the "Is-Ought Gap" (or "Hume's Law")?
A: "No ought-judgment may be correctly inferred from a set of premises expressed only in terms of 'is'." (Page 12).

Q: What is the key feature of "Inductive Arguments"?
A: They are "risky arguments," meaning the premises do not guarantee the conclusion (Page 14).

Q: What is the main aim of "Classical AI"?
A: To build artificial machines that have intelligence, holding that any feature of human intelligence can be built into a machine (Page 18).

Q: What is the claim of "Strong AI"?
A: That the AI *actually* has a mind and cognition (Page 18).

Q: What is "Artificial General Intelligence" (AGI)?
A: The ambition to recreate human or superhuman intelligence using the methodology of Technical AI (Page 19).

Q: What are two main arguments that intelligence is "computation-plus" (i.e., computation alone is not enough)?
A: The 4E argument (intelligence must be embodied and interact with the environment) and the Chinese room argument (intelligence requires intentionality) (Page 21).

Q: What is the "Chinese room argument" (by John Searle)?
A: It's an argument that computation alone is not enough for intelligence; it must also have "intentionality" (or understanding) (Page 21).

Q: What is the logical structure of an argument from "necessary conditions"?
A: 1. E is strongly intelligent only if E can learn and reason. 2. AI does not have that capacity. 3. Therefore, AI is not strongly intelligent. (This is *modus tollens*) (Page 23).

Q: What is the logical structure of an argument from "sufficient conditions"?
A: 1. If E has such-and-such a capacity, E is a person. 2. AI has that capacity. 3. Therefore, AI is a person. (This is *modus ponens*) (Page 24).

Q: What are some candidate necessary conditions for "personhood"?
A: Consciousness, Selfhood, Responsibility, and Goal-setting (Page 25).

Q: What is the moral significance of "personhood"?
A: Being a person is considered a basic kind of moral status, requiring respect or possessing rights (Page 25).


Overview: Second lecture
Date: 4 Sep 2025