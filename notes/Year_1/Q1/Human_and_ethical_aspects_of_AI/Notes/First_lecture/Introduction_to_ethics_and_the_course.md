# Human and ethical aspects of AI - Lecture 1

Written assignment (50%) & written (essay) exam (50%)

Q: Why is ethics relevant to AI design?
A: Because AI systems support or replace human decision-making, and ethics aims to answer how decisions should be made. (Page 5)

Q: What four features of AI require special ethical attention?
A: Speed, scale, opacity, and independence of human oversight. (Page 5)

Q: What forms the main source of exam questions?
A: The overlap between the lectures and the readings. (Page 6)

Q: What types of questions will be on the final exam?
A: Both open (short paragraph) and closed (MC/T-F) questions. (Page 6)

Q: What are the two ways to arrive at a correct answer on the exam?
A: 1) Remember points directly from readings and lectures, or 2) Reason to the correct answer from your understanding of the material. (Page 6)

Q: What is the definition of ethics provided in the lecture?
A: Ethics is defined as the systematic study of morality. (Page 8)

Q: What are the three levels in the structure of ethics?
A: 1) Judgments in concrete cases (morality), 2) Principles, values, virtues (ethics), 3) Theories. (Page 9)

Q: What is "Wide reflective equilibrium"?
A: It refers to the need to take science and empirical factors into account when seeking "reflective equilibrium" between ethical judgments, principles, and theories. (Page 9)

Q: What are the three available assignment topics?
A: AI-generated ethics cases [EC], AI for ethics review [AIER], and AI for Eating Disorder Symptoms [EDS]. (Page 10)

Q: What must students produce at the end of the first three weeks for the assignment?
A: An initial report describing the motivation, goals, requirements, and anticipated issues of the project. (Page 10)

Q: What is the primary reading for the course?
A: The first section of "The Cambridge Handbook of the Law, Ethics and Policy of Artificial Intelligence" (Smuha NA, ed. 2025). (Page 11)

Q: What are the two fundamental sources discussed in the lecture?
A: The Universal Declaration of Human Rights (1948) and The Belmont Report (1979). (Page 15)

Q: When and why was the Universal Declaration of Human Rights (UDHR) created?
A: It was created by the United Nations in 1948 in response to the moral atrocities committed in World War II. (Page 16)

Q: What does Article 12 of the UDHR protect against?
A: Arbitrary interference with privacy, family, home, or correspondence, and attacks upon honour and reputation. (Page 17)

Q: What is the logical relationship that defines a negative right?
A: $R$ has a right to $X \rightarrow S$ has a duty not to interfere with X. (Page 18)

Q: What is the logical relationship that defines a positive right?
A: $R$ has a right to $X \rightarrow S$ has a duty to provide X. (Page 18)

Q: What is S. Matthew Liao's "Fundamental Conditions Approach" [FCA] to human rights?
A: It states that "human rights protect the fundamental conditions for pursuing a good life". (Page 20)

Q: What is the full title of The Belmont Report?
A: Ethical Principles and Guidelines for the Protection of Human Subjects of Research. (Page 22)

Q: What is a key difference in how the Belmont Report and the UDHR are framed?
A: The Belmont Report is framed in terms of ethics principles rather than rights. (Page 23)

Q: What is a key similarity between the Belmont Report and the UDHR?
A: Both were written as a response to serious moral failures and resulted from a process of consensus building. (Page 23)

Q: What are the "Four Principles" of the approach derived from the Belmont Report?
A: Beneficence, Non-maleficence, Respect, and Justice. (Page 24)

Q: Why were the principles of Respect and Justice needed in addition to beneficence and non-maleficence?
A: Because beneficence and non-maleficence did not fully explain the wrongness of cases like Tuskegee (i.e., "using people"). (Page 27)

Q: What is an ERB?
A: An Ethical Review Board, which must approve all human subjects research. (Page 28)

Q: In what two ways is Artificial Intelligence considered human subjects research?
A: 1) The data it processes is about humans, and 2) The knowledge acquired is used to drive decisions that affect human beings. (Page 29)

Q: What ethical issue was raised about facial-recognition research in the *Nature* article?
A: Most scientists now collect facial images (e.g., from webcams) without asking permission. (Page 30)

Q: According to the Belmont Report, what are the two ethical convictions within "Respect for persons"?
A: 1) Individuals should be treated as autonomous agents, and 2) persons with diminished autonomy are entitled to protection. (Page 32)

Q: According to the Belmont Report, what question does the principle of "Justice" ask?
A: "Who ought to receive the benefits of research and bear its burdens?" (Page 32)

Q: According to EU draft guidelines, if a person makes a photograph public, does this also make the *biometric data* from that photo public?
A: No, it does not. (Page 33)

Q: What is the general approach the EU takes to AI policy?
A: A RISK-Based approach. (Page 34)

Q: The EU's Ethical AI approach is based on "Four Principles Plus One". What is the "Plus One"?
A: Explicability (explainability). (Page 34)

Q: What are "ethics cases" used for in ethics education?
A: They are descriptions of a situation used for the purpose of eliciting moral intuitions or reactions. (Page 39)

Q: What is a primary challenge with traditional ethics review that AI-supported review (Topic 2) aims to address?
A: Ethics review takes up considerable resources and causes delays because it is highly text-intensive. (Page 41)

Q: What is "EthicAlly"?
A: A research project and prototype (using Claude.ai) to explore how AI can support research ethics planning and review. (Page 45)

Q: What is the stated aim of the EthicAlly project?
A: To create a not-for-profit resource to provide ethics support, especially in under-resourced regions. (Page 45)

Q: What type of research can the EthicAlly beta tool *not* review?
A: Clinical research. (Page 46)

Q: What is the main research question for Topic 3, concerning the "fEATback" tool?
A: How an AI tool could be developed to support patients, family, or the public, as the current chat interface is not AI-based. (Page 50)

Q: What is "techno-solutionism" (Siffels & Sharon 2024)?
A: "The problem definition follows the solution and is twisted to fit the solution, rather than the other way around". (Page 51)

Overview: First lecture
Date: 2 Sep 2025