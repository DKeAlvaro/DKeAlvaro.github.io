# Responsibility and AI - Lecture 5

Q: What are the four main notions of responsibility?
A: Passive (backward-looking) moral responsibility, Active (forward-looking) moral responsibility, Collective moral responsibility, and Legal responsibility (Page 2).

Q: What is another name for passive moral responsibility?
A: Backward-looking moral responsibility or blameworthiness (Page 4).

Q: What are the four conditions for passive (backward-looking) moral responsibility?
A: Causal Contribution, Freedom of Action, Foreseeability, and Wrong-doing (Page 4).

Q: When are people or companies responsible for risk in the passive sense?
A: When they causally contribute (increase probability of a bad outcome), act freely, are (or should be) aware of the hazard, and the resulting risk is not acceptable (Page 6).

Q: What is the "many hands problem"?
A: A situation in which a collective may reasonably be held responsible for an outcome, but no individual may reasonably be held responsible for that outcome (Page 8).

Q: What is a "responsibility gap"?
A: A situation where it seems we ought to hold somebody responsible, but we cannot reasonably hold anybody responsible (Page 9).

Q: How can the "many hands problem" be addressed?
A: By motivating the importance of a clearer assignment of active responsibility, sometimes using technology or law (Page 10).

Q: What is "active moral responsibility" (or "role responsibility")?
A: It is "active" in that it anticipates who is responsible in the future by giving a person a particular role that requires tasks (Page 11).

Q: What example does the lecture give of technology partially automating role responsibility?
A: Uber requiring drivers to take selfies for added security to verify their identity (Page 12).

Q: In the table of distributed role responsibilities, what is the role of the "Platform designer (Software engineer)"?
A: To provide tools for drivers and anticipate technical and security gaps (Page 13).

Q: What are the three values mentioned for the distribution of active responsibility?
A: Feasibility, Transparency to outsiders, and Fairness (Page 14).

Q: What does it mean to be assigned "active/forward-looking responsibility"?
A: The responsible party puts herself in a position where she will have the ability to act, know what norms apply, adequately perceive violations, and consider the consequences (Page 15).

Q: What are the two types of legal responsibility mentioned?
A: Type 1: Criminal responsibility, and Type 2: Liability (Page 18).

Q: What is "liability" in a legal sense?
A: Backward-looking legal responsibility in which the responsible party must pay a fine, arrange repair, or pay damages (Page 18).

Q: In the 2018 Uber self-driving car crash, who was held *not* criminally responsible?
A: Uber Technologies Inc (Page 19).

Q: In that same Uber crash, who could have faced charges and why?
A: The back-up driver, Rafaela Vasquez, who was reportedly watching streaming TV and did not react in time (Page 19).

Q: What is the difference between moral responsibility and legal liability?
A: Moral responsibility is informal and connected to blame/emotions, while legal liability is formal (in a court of law) and connected to fines/damages (Page 22).

Q: What is "negligence" as a condition for legal liability?
A: It is the usual condition for legal liability (Page 23).

Q: What are the four elements required to prove negligence?
A: A duty of care, a breach of the duty, injury or damage, and a causal connection between the breach and the injury/damage (Page 23).

Q: How is "foreseeability" understood in negligence cases?
A: By the "reasonable person standard": what a reasonable person in the defendant's position could have foreseen (Page 23).

Q: What is "strict liability"?
A: A standard where the defendant is liable if they engaged in a risky activity that caused injury or damage, even without needing to show negligence (Page 24).

Q: What is "product liability"?
A: A kind of strict liability where manufacturers are liable for defects in a product, without the need to show negligence (Page 24).

Q: What is the "development risks" defense in the EU Standard for Product Liability?
A: A producer is not liable if they prove that "the state of scientific and technical knowledge at the time when he put the product into circulation was not such as to enable the existence of the defect to be discovered" (Page 25).

Q: What is the EU's justification for "liability without fault" (product liability)?
A: It is the "sole means of adequately solving the problem... of a fair apportionment of the risks inherent in modern technological production" (Page 26).

Q: What is "limited liability" for a corporation?
A: Shareholders may only be liable up to the value of their shares (Page 27).

Q: How does the lecture summarize the relationships between the four types of responsibility?
A: Passive moral responsibility is basic; Active moral responsibility is about taking responsibility for future events; Legal responsibility concerns justice (punishment/compensation); Collective responsibility responds to the "many hands problem" (Page 28).

Q: What is the difference between "actions" and "omissions" in responsibility?
A: Actions are intentional behaviors with a causal impact, while omissions are non-actions or failures to act (Page 30).

Q: What is a "failure condition"?
A: A scenario in which some element or person does not behave according to the "script" (desired operating conditions), with a potentially bad outcome as a result (Page 32).

Q: Why can a machine apparently not be responsible?
A: Because responsibility contains a freedom condition that machines do not satisfy, and there is a "retribution gap" (it doesn't make sense to blame or punish a machine) (Page 35).

Q: What is a "script" in the context of design and responsibility?
A: The choices made by designers about what should be delegated to a machine and what should be left to the initiative of human actors (Page 38, Page 39).

Q: What are three potential solutions for dealing with responsibility and failure conditions?
A: Write clearer/broader scripts, insulate the system from failure conditions, and enforce the scripts (Page 41).

Overview: Fifth lecture
Date: 16 Sep 2025